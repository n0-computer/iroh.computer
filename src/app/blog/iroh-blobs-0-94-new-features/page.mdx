import { BlogPostLayout } from '@/components/BlogPostLayout'
import { MotionCanvas } from '@/components/MotionCanvas'

export const post = {
  draft: false,
  author: 'rklaehn',
  date: '2025-10-02',
  title: 'iroh-blobs 0.94 - New features',
  description: 'Learn about the new features in the new blobs API',
}

export const metadata = {
    title: post.title,
    description: post.description,
    openGraph: {
      title: post.title,
      description: post.description,
      images: [{
        url: `/api/og?title=Blog&subtitle=${post.title}`,
        width: 1200,
        height: 630,
        alt: post.title,
        type: 'image/png',
      }],
      type: 'article'
    }
}

export default (props) => <BlogPostLayout article={post} {...props} />

# New features in iroh-blobs

Iroh-blobs 0.94 contains a number of significant new features that are worth explaining in detail. Unfortunately it still does not contain per-blob multiprovider, which we originally promised for mid September. Sorry about this. But there are several new features that are useful for blobs users and also for iroh users in general.

Let's start with a feature that is essential for blobs itself, but can also be useful for many other protocols.

## Connection pool

There is a new connection pool in `util::connection_pool`. This is useful whenever you have a protocol that has to talk to a large number of endpoints while keeping an upper bound of concurrent open connections. In blobs this is used whenever you use the downloader to orchestrate blobs downloads from multiple providers.

Iroh connections are relatively lightweight, but even so you don't want to keep thousands of them open at the same time. But opening a new connection every time you do a small exchange with a peer is very wasteful. The ConnectionPool gives you an API to deal with these tradeoffs.

### Basic usage

Let's first look at basic usage:

```rust
let pool = ConnectionPool::new(ep, iroh_blobs::ALPN, Options::default());
let conn = pool.get_or_connect(remote_id)?;
/// use the connection as usual.
```

`get_or_connect` will try to get an existing connection from the pool. If there is none, it will create one and store it. The connection will be kept in the pool for a configurable time. Idle connections will be closed as needed. So you can just use this as a drop-in replacement for endpoint.connect and be sure that you won't ever create an unbounded number of connections.

### Advanced features

There are some advanced features that can be configued using non-default options.

```rust
pub struct Options {
    pub idle_timeout: Duration,
    pub connect_timeout: Duration,
    pub max_connections: usize,
    pub on_connected: Option<OnConnected>,
}
```

You can configure the max number of connections to be retained, the maximum tolerable duration for connection establishment, and the max duration connections are kept when idle. So far, pretty straightforward. There is an additional option to perform some setup before the connection is handed out to the user. For example you can reject connections based on the data available at this time from the endpoint and the connection, or wait for the connection to reach a certain state before handing it out.

As an example, you might want to do iroh-blobs transfers only on direct connections in order to get good performance or reduce bandwith use on the relay. If establishing direct connections is not possible, the connection establishment would time out, and you would never even attempt a transfer from such a node.

```rust
let on_connected = |ep: Endpoint, conn: Connection| async move {
    let Ok(id) = conn.remote_node_id() else {
        return Err(io::Error::other("unable to get node id"));
    };
    let Some(watcher) = ep.conn_type(id) else {
        return Err(io::Error::other("unable to get conn_type watcher"));
    };
    let mut stream = watcher.stream();
    while let Some(status) = stream.next().await {
        if let ConnectionType::Direct { .. } = status {
            return Ok(());
        }
    }
    Err(io::Error::other("connection closed before becoming direct"))
};
let options = Options::default().with_on_connected(on_connected);
let pool = ConnectionPool::new(ep, iroh_blobs::ALPN, options);

let conn = pool.get_or_connect(remote_id)?;
/// use the connection as usual.
```

We had this exact problem at a customer, where we wanted to avoid spamming the relay with gigabytes of blob transfers before getting a direct connection to avoid overloading the relay and slowing down the more important control plane gossip messages.

The code to await a direct connection will change quite a bit once we have QUIC multipath. But the capability will remain, and we will update the test code to reflect the new API.

<Note>
The connection pool is generic enough that it will move to its own crate together with some other iroh utilities. It lives in blobs only until iroh 1.0 is released.

Until then, just depend in iroh-blobs. Iroh-blobs without persistent storage is a very lightweight dependency.
</Note>

One thing to keep in mind when using the connection pool: the connection pool needs the ability to track which connections are currently being used. To do this, the connection pool does not return `Connection` but `ConnectionRef`, a struct that derefs to `Connection` but contains some additional lifetime tracking.

But `Connection` is `Clone`, so in principle there is nothing stopping you from cloning the wrapped connection and losing the lifetime tracking. **Don't do this**. If you work with connections from the pool, you should pass around either a `ConnectionRef` or a `&Connection` to make sure the underlying `ConnectionRef` stays alive.

We experimented with a safer callback-based API, but it turned out to be just too inconvenient to use.

## Abstract request and response streams

Iroh-blobs is a protocol that tries to avoids overabstraction. For example as of now you can only use the BLAKE3 hash function, and we hardcode the chunk group size to a value that should work well for all users.

But sometimes there are cases where a bit of abstraction is needed. There was a user request to be able to use compression with iroh-blobs in [sendme]. One way to do this is to compress files before adding them to the blob store. But this has various downsides. It requires you to create a copy of all data before adding it to the blob store, and will also not lead to very good compression rates when dealing with a large number of small files, since each file will have to be compressed in isolation.

What would be better would be to compress requests and response streams of the entire protocol and expose the resulting protocol under a different ALPN. With this approach the compression algorithm would be able to find redundancies between multiple files when handling a request for multiple blobs.

This was previously impossible since iroh-blobs worked directly with `iroh::endpoint::SendStream` and `iroh::endpoint::RecvStream`. So we added a lightweight stream abstraction to 